{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "#from deepface.modules import functions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "from time import time\n",
    "\n",
    "# Local descriptors\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage import  exposure\n",
    "from skimage import feature\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPredictions(X_train, X_test, y_train, y_test, model, parameters):\n",
    "    model_name = type(model).__name__\n",
    "    print(f\"{model_name} training...\")\n",
    "    t0 = time()\n",
    "    \n",
    "    # Grid search across parameter range\n",
    "    clf = GridSearchCV(model, parameters, cv=5)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(clf.best_estimator_)\n",
    "\n",
    "    print(\"Predicting\")\n",
    "    t0 = time()\n",
    "    # test labels\n",
    "    y_pred = clf.predict(X_test)\n",
    "   \n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    \n",
    "    return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_embs(model, X):\n",
    "    norm_images = prewhiten(X)\n",
    "    pd = []\n",
    "    for image in norm_images:\n",
    "        pd.append(model.forward(np.expand_dims(image, axis=0)))\n",
    "    return l2_normalize(np.concatenate(pd))\n",
    "\n",
    "def l2_normalize(x, axis=-1, epsilon=1e-10):\n",
    "    output = x / np.sqrt(np.maximum(np.sum(np.square(x), axis=axis, keepdims=True), epsilon))\n",
    "    return output\n",
    "\n",
    "def prewhiten(x):\n",
    "    if x.ndim == 4:\n",
    "        axis = (1, 2, 3)\n",
    "        size = x[0].size\n",
    "    elif x.ndim == 3:\n",
    "        axis = (0, 1, 2)\n",
    "        size = x.size\n",
    "    else:\n",
    "        raise ValueError('Dimension should be 3 or 4')\n",
    "\n",
    "    mean = np.mean(x, axis=axis, keepdims=True)\n",
    "    std = np.std(x, axis=axis, keepdims=True)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
    "    y = (x - mean) / std_adj\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_with_error_handling(dest_folder, class_name, n_images, image):\n",
    "    try:\n",
    "        cv2.imwrite(os.path.join(dest_folder, os.path.join(class_name, str(n_images) + '_faces.jpg')), image)\n",
    "    except cv2.error as e:\n",
    "        print(f\"An error occurred while saving image {str(n_images)}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data location\n",
    "folder = \"data/rvf10k/train\"\n",
    "dest_folder = \"data/roi_dataset\"\n",
    "cascade_path = \"data/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Counter for the number of classes in the dataset\n",
    "nclasses = 0\n",
    "# Counter for samples per class\n",
    "nperclass = []\n",
    "# Label for each class (name of the subfolder)\n",
    "classlabels = []\n",
    "\n",
    "n_images = 0\n",
    "\n",
    "# Assumes that there is a subfolder per class in the given path\n",
    "for class_name in os.listdir(folder):\n",
    "    # Each subfolder implies one more class\n",
    "    nclasses += 1\n",
    "    # Initially, this class has no samples\n",
    "    nsamples = 0\n",
    "\n",
    "    # Compose the path\n",
    "    class_folder = os.path.join(folder, class_name)\n",
    "    for file_name in os.listdir(class_folder):\n",
    "        # Assumes images are in jpg format\n",
    "        if file_name.endswith('.jpg'):\n",
    "            # Read the image\n",
    "            image = cv2.imread(os.path.join(class_folder, file_name))\n",
    "\n",
    "            # Extract face as ROI\n",
    "            faceCascade = cv2.CascadeClassifier(cascade_path)\n",
    "            faces = faceCascade.detectMultiScale(\n",
    "                image,\n",
    "                scaleFactor=1.3,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30)\n",
    "            )\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                for x, y, w, h in faces:\n",
    "                    image = image[y:y + h, x:x + w]\n",
    "                    save_image_with_error_handling(dest_folder, class_name, n_images, image)\n",
    "                    n_images += 1\n",
    "            else:\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(dest_folder, os.path.join(class_name, str(n_images) + '_faces.jpg')), image)\n",
    "                n_images += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "\n",
    "# def preprocess_image_for_facenet(image):\n",
    "#     \"\"\"\n",
    "#     Preprocesses an image for FaceNet model:\n",
    "#     - Resizes the image to the expected input size of the model (160x160).\n",
    "#     - Applies histogram equalization for contrast enhancement.\n",
    "#     - Applies sharpening filter to enhance details.\n",
    "#     - Normalizes image values to the range [-1, 1].\n",
    "    \n",
    "#     Args:\n",
    "#     - image: Input image.\n",
    "    \n",
    "#     Returns:\n",
    "#     - preprocessed_image: Preprocessed image.\n",
    "#     \"\"\"\n",
    "#     # Scaling to the expected input size of the model (160x160)\n",
    "#     target_size = (160, 160)\n",
    "#     resized_image = cv2.resize(image, target_size)\n",
    "    \n",
    "#     # Histogram equalization for contrast enhancement\n",
    "#     if len(resized_image.shape) == 3 and resized_image.shape[2] == 3:\n",
    "#         ycrcb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2YCrCb)\n",
    "#         channels = cv2.split(ycrcb)\n",
    "#         cv2.equalizeHist(channels[0], channels[0])\n",
    "#         cv2.merge(channels, ycrcb)\n",
    "#         resized_image = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "#     else:\n",
    "#         resized_image = cv2.equalizeHist(resized_image)\n",
    "    \n",
    "#     # Sharpening the images\n",
    "#     kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "#     sharpened_image = cv2.filter2D(resized_image, -1, kernel)\n",
    "    \n",
    "#     # Normalizing image values to the range [-1, 1]\n",
    "#     normalized_image = sharpened_image / 127.5 - 1\n",
    "    \n",
    "#     return normalized_image\n",
    "\n",
    "# # Face detection and alignment without dlib\n",
    "# def align_face(image):\n",
    "#     \"\"\"\n",
    "#     Detects and aligns face in the image.\n",
    "    \n",
    "#     Args:\n",
    "#     - image: Input image.\n",
    "    \n",
    "#     Returns:\n",
    "#     - face_roi: Cropped face region of interest.\n",
    "#     \"\"\"\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "#     faces = faceCascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "#     if len(faces) > 0:\n",
    "#         x, y, w, h = faces[0]\n",
    "#         face_roi = image[y:y + h, x:x + w]\n",
    "#         return face_roi\n",
    "#     else:\n",
    "#         return image\n",
    "\n",
    "# def save_image_with_error_handling(dest_folder, class_name, n_images, image):\n",
    "#     \"\"\"\n",
    "#     Saves an image with error handling.\n",
    "    \n",
    "#     Args:\n",
    "#     - dest_folder: Destination folder for saving the image.\n",
    "#     - class_name: Name of the class (subfolder).\n",
    "#     - n_images: Image index.\n",
    "#     - image: Image to be saved.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         os.makedirs(os.path.join(dest_folder, class_name), exist_ok=True)\n",
    "#         cv2.imwrite(os.path.join(dest_folder, class_name, str(n_images) + '_faces.jpg'), image)\n",
    "#     except cv2.error as e:\n",
    "#         print(f\"An error occurred while saving image {str(n_images)}: {e}\")\n",
    "\n",
    "# # Data location\n",
    "# folder = \"data/rvf10k/train\"\n",
    "# dest_folder = \"data/roi_dataset\"\n",
    "# cascade_path = \"data/haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# # Counter for the number of classes in the dataset\n",
    "# nclasses = 0\n",
    "# # Counter for samples per class\n",
    "# nperclass = []\n",
    "# # Label for each class (name of the subfolder)\n",
    "# classlabels = []\n",
    "\n",
    "# n_images = 0\n",
    "\n",
    "# # Assumes that there is a subfolder per class in the given path\n",
    "# for class_name in os.listdir(folder):\n",
    "#     # Each subfolder implies one more class\n",
    "#     nclasses += 1\n",
    "#     # Initially, this class has no samples\n",
    "#     nsamples = 0\n",
    "\n",
    "#     # Compose the path\n",
    "#     class_folder = os.path.join(folder, class_name)\n",
    "#     for file_name in os.listdir(class_folder):\n",
    "#         # Assumes images are in jpg format\n",
    "#         if file_name.endswith('.jpg'):\n",
    "#             # Read the image\n",
    "#             image = cv2.imread(os.path.join(class_folder, file_name))\n",
    "\n",
    "#             # Extract face as ROI\n",
    "#             faceCascade = cv2.CascadeClassifier(cascade_path)\n",
    "#             faces = faceCascade.detectMultiScale(\n",
    "#                 image,\n",
    "#                 scaleFactor=1.3,\n",
    "#                 minNeighbors=5,\n",
    "#                 minSize=(30, 30)\n",
    "#             )\n",
    "\n",
    "#             if len(faces) > 0:\n",
    "#                 for x, y, w, h in faces:\n",
    "#                     face_roi = image[y:y + h, x:x + w]\n",
    "#                     aligned_face = align_face(face_roi)\n",
    "#                     preprocessed_face = preprocess_image_for_facenet(aligned_face)\n",
    "#                     save_image_with_error_handling(dest_folder, class_name, n_images, preprocessed_face)\n",
    "#                     n_images += 1\n",
    "#             else:\n",
    "#                 aligned_image = align_face(image)\n",
    "#                 preprocessed_image = preprocess_image_for_facenet(aligned_image)\n",
    "#                 cv2.imwrite(\n",
    "#                     os.path.join(dest_folder, os.path.join(class_name, str(n_images) + '_faces.jpg')), preprocessed_image)\n",
    "#                 n_images += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepface\n",
    "# Available models ['VGG-Face', 'Facenet', 'OpenFace', 'DeepFace', 'DeepID', 'Dlib']\n",
    "model_deepface = DeepFace.build_model(\"Facenet\")\n",
    "\n",
    "target_size = (model_deepface.input_shape[0], model_deepface.input_shape[1])\n",
    "dim = (int(target_size[0]), int(target_size[1]))\n",
    "\n",
    "# Data location\n",
    "folder = \"data/roi_dataset\"\n",
    "\n",
    "# Counter for the number of classes in the dataset\n",
    "nclasses = 0\n",
    "# Counter for samples per class\n",
    "nperclass = []\n",
    "# Label for each class (name of the subfolder)\n",
    "classlabels = []\n",
    "# Initialize data structures and their corresponding labels\n",
    "X = []\n",
    "Y = []\n",
    "XFaceNet = []\n",
    "\n",
    "# Default resolution value for matplotlib\n",
    "dpi = matplotlib.rcParams['figure.dpi']\n",
    "# Number of sample images from each class to show\n",
    "nims2show = 5\n",
    "\n",
    "# Assumes that there is a subfolder per class in the given path\n",
    "for class_name in os.listdir(folder):\n",
    "    # Each subfolder implies one more class\n",
    "    nclasses += 1\n",
    "    # Initially, this class has no samples\n",
    "    nsamples = 0\n",
    "\n",
    "    # Compose the path\n",
    "    class_folder = os.path.join(folder, class_name)\n",
    "    for file_name in os.listdir(class_folder):\n",
    "        # Assumes images are in jpg format\n",
    "        if file_name.endswith('.jpg'):\n",
    "            # Read the image\n",
    "            image = cv2.imread(os.path.join(class_folder, file_name))\n",
    "            \n",
    "            # Extract sizes\n",
    "            height, width, depth = image.shape\n",
    "            # Convert to grayscale\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            X.append(gray.reshape(height * width))\n",
    "            \n",
    "            # Deepface with FaceNet\n",
    "            # Get embeddings\n",
    "            img_embedding = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "            img_embedding = calc_embs(model_deepface, np.expand_dims(img_embedding, axis=0))\n",
    "            XFaceNet.append(img_embedding[0])\n",
    "                    \n",
    "            # Add numerical label of the sample\n",
    "            Y.append(nclasses - 1)\n",
    "            \n",
    "            # Show the first nims2show samples of each class\n",
    "            if nsamples < nims2show:\n",
    "                if nsamples == 0:\n",
    "                    figsize = 15 * width / float(dpi), 15 * height / float(dpi)\n",
    "                    fig = plt.figure(figsize=figsize)\n",
    "                \n",
    "                fig.add_subplot(1, nims2show, nsamples + 1)\n",
    "                plt.imshow(gray, cmap='gray', vmin=0, vmax=255)\n",
    "            \n",
    "            # Increase the number of samples\n",
    "            nsamples += 1\n",
    "    plt.show()\n",
    "    nperclass.append(nsamples)\n",
    "    classlabels.append(class_name)\n",
    "    \n",
    "# Convert X and Y to numpy arrays\n",
    "Y = np.array(Y, dtype='float64')\n",
    "XFaceNet = np.array(XFaceNet, dtype='float32')\n",
    "\n",
    "# Show information about the read dataset\n",
    "# Debugging\n",
    "print(\"Features\")\n",
    "print(XFaceNet.shape)\n",
    "print(Y.shape)\n",
    "# Get number of samples and features\n",
    "# Get names of the classes\n",
    "class_names = np.array(classlabels)\n",
    "n_classes = class_names.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, random_state=7, shuffle=True)\n",
    "\n",
    "# Store file paths\n",
    "file_paths = []\n",
    "for class_name in os.listdir(folder):\n",
    "    class_folder = os.path.join(folder, class_name)\n",
    "    for file_name in os.listdir(class_folder):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            file_paths.append(os.path.join(class_folder, file_name))\n",
    "\n",
    "folds = [[] for _ in range(5)]\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    print(\"Fold %d\" % fold)\n",
    "    print(\"# samples in training set %d\" % train_index.shape[0])\n",
    "    print(\"# samples in test set %d\" % test_index.shape[0])\n",
    "    \n",
    "    fold_files = [file_paths[i] for i in test_index]\n",
    "    folds[fold - 1] = fold_files\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# Save file paths to a file\n",
    "with open('folds.txt', 'w') as f:\n",
    "    for i, fold_files in enumerate(folds):\n",
    "        f.write(f\"Files in fold {i + 1}:\\n\")\n",
    "        for file_path in fold_files:\n",
    "            f.write(file_path + '\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "# Folds are also saved in the variable 'folds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze images. Save imagepath to another file if no face found. Summarize results\n",
    "analysis_results = []\n",
    "failed_images = []\n",
    "\n",
    "for i, fold_files in enumerate(folds):\n",
    "    fold_results = defaultdict(lambda: defaultdict(int))\n",
    "    for file_path in fold_files:\n",
    "        try:\n",
    "            objs = DeepFace.analyze(img_path=file_path, actions=['age', 'gender', 'race', 'emotion'])\n",
    "            for obj in objs:  # iterate through the list of analysis results\n",
    "                for key, value in obj.items():\n",
    "                    if key in ['age', 'gender', 'race', 'emotion']:\n",
    "                        if isinstance(value, dict):  # e.g., emotion analysis returns a dictionary\n",
    "                            for sub_key, sub_value in value.items():\n",
    "                                fold_results[key][sub_key] += sub_value\n",
    "                        else:\n",
    "                            fold_results[key][value] += 1\n",
    "        except ValueError as e:\n",
    "            print(f\"Failed to analyze {file_path}: {e}\")\n",
    "            failed_images.append(file_path)\n",
    "    analysis_results.append(fold_results)\n",
    "\n",
    "# Save analysis results to a file\n",
    "with open('analysis_summary.txt', 'w') as f:\n",
    "    for i, fold_results in enumerate(analysis_results):\n",
    "        f.write(f\"Summary for fold {i + 1}:\\n\")\n",
    "        for key, value in fold_results.items():\n",
    "            f.write(f\"{key}:\\n\")\n",
    "            for sub_key, sub_value in value.items():\n",
    "                f.write(f\"  {sub_key}: {sub_value}\\n\")\n",
    "        f.write('\\n')\n",
    "\n",
    "# Save failed images to a file\n",
    "with open('failed_images.txt', 'w') as f:\n",
    "    f.write(\"Images where face detection failed:\\n\")\n",
    "    for file_path in failed_images:\n",
    "        f.write(file_path + '\\n')\n",
    "\n",
    "# Print analysis results (optional)\n",
    "for i, fold_results in enumerate(analysis_results):\n",
    "    print(f\"Summary for fold {i + 1}:\")\n",
    "    for key, value in fold_results.items():\n",
    "        print(f\"{key}:\")\n",
    "        for sub_key, sub_value in value.items():\n",
    "            print(f\"  {sub_key}: {sub_value}\")\n",
    "    print('\\n')\n",
    "\n",
    "# Print failed images (optional)\n",
    "print(\"Images where face detection failed:\")\n",
    "for file_path in failed_images:\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"+++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "\n",
    "# KNN \n",
    "precs_facenet_svm, recs_facenet_svm, acc_facenet_svm = [], [], []\n",
    "\n",
    "precs_facenet_rf, recs_facenet_rf, acc_facenet_rf = [], [], []\n",
    "\n",
    "SVM = SVC(kernel='rbf', class_weight='balanced')\n",
    "SVM_parameters = {\n",
    "    'C': [1e3, 5e3],\n",
    "    'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01],\n",
    "}\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "RF_parameters = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "}\n",
    "\n",
    "fold = 1\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    print(\"*********************\\nFold %d\" % fold)\n",
    "        \n",
    "    # Facenet - SVM\n",
    "    print(\"\\nDeepface/Facenet\")\n",
    "    XFaceNet = XFaceNet.reshape(-1, 1)\n",
    "    y_pred, y_test = GetPredictions(XFaceNet[train_index], XFaceNet[test_index], Y[train_index], Y[test_index], SVM, SVM_parameters)\n",
    "    print(\"\\nDeepface/Facenet + SVM Metrics\")\n",
    "    precs_facenet_svm.append(precision_score(y_test, y_pred))\n",
    "    recs_facenet_svm.append(recall_score(y_test, y_pred))\n",
    "    acc_facenet_svm.append(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "    print(\"Confusion matrix for Facenet + SVM:\")\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=range(n_classes))\n",
    "    print(cm)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "        \n",
    "    # Facenet - Random Forest\n",
    "    y_pred, y_test = GetPredictions(XFaceNet[train_index], XFaceNet[test_index], Y[train_index], Y[test_index], RF, RF_parameters)\n",
    "    print(\"\\nDeepface/Facenet + RF Metrics\")\n",
    "    precs_facenet_rf.append(precision_score(y_test, y_pred))\n",
    "    recs_facenet_rf.append(recall_score(y_test, y_pred))\n",
    "    acc_facenet_rf.append(accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "    print(\"Confusion matrix for Facenet + RF:\")\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=range(n_classes))\n",
    "    print(cm)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "        \n",
    "    fold += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
